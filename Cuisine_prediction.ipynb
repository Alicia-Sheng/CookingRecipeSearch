{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55b57f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score, cross_val_predict, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1edad9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [  \n",
    "#         'GradientBoostingRegressor',\n",
    "        'LDA',\n",
    "        'Nearest Neighbors',\n",
    "#         'AdaBoostClassifier',\n",
    "#         'RandomForest',\n",
    "#         \"Linear SVM\",\n",
    "        \"RBF SVM\",\n",
    "#         \"Decision Tree\",\n",
    "#         \"sLDA\",\n",
    "#         \"MLP\",\n",
    "#         'RUSBoost',\n",
    "        ]\n",
    "\n",
    "# build classifiers\n",
    "classifiers = [\n",
    "#             GradientBoostingRegressor(random_state=1),\n",
    "            LinearDiscriminantAnalysis(),\n",
    "            KNeighborsClassifier(n_neighbors=20),\n",
    "#             AdaBoostClassifier(n_estimators=400, learning_rate = 0.6),\n",
    "#             RandomForestClassifier(),\n",
    "#             SVC(kernel=\"linear\", C=0.025),\n",
    "            SVC(gamma=2, C=1),\n",
    "#             DecisionTreeClassifier(),\n",
    "#             LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'),\n",
    "#             MLPClassifier(random_state=1, max_iter=300),\n",
    "#             RUSBoostClassifier(n_estimators = 200, random_state=1),\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf450d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>0.463036</td>\n",
       "      <td>0.043366</td>\n",
       "      <td>0.148925</td>\n",
       "      <td>-0.274926</td>\n",
       "      <td>0.652883</td>\n",
       "      <td>0.115647</td>\n",
       "      <td>-0.791759</td>\n",
       "      <td>-0.007681</td>\n",
       "      <td>0.531001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354413</td>\n",
       "      <td>-0.316524</td>\n",
       "      <td>0.198050</td>\n",
       "      <td>-0.035833</td>\n",
       "      <td>0.038994</td>\n",
       "      <td>0.123171</td>\n",
       "      <td>-0.514503</td>\n",
       "      <td>-0.409309</td>\n",
       "      <td>0.312318</td>\n",
       "      <td>greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>0.223341</td>\n",
       "      <td>0.731181</td>\n",
       "      <td>0.343865</td>\n",
       "      <td>0.254070</td>\n",
       "      <td>0.232782</td>\n",
       "      <td>-0.089698</td>\n",
       "      <td>-0.678553</td>\n",
       "      <td>0.145089</td>\n",
       "      <td>-0.042785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029557</td>\n",
       "      <td>0.033568</td>\n",
       "      <td>0.062671</td>\n",
       "      <td>-0.010367</td>\n",
       "      <td>-0.152798</td>\n",
       "      <td>-0.075444</td>\n",
       "      <td>-0.185032</td>\n",
       "      <td>-0.040249</td>\n",
       "      <td>-0.040383</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>0.411820</td>\n",
       "      <td>0.636279</td>\n",
       "      <td>0.355501</td>\n",
       "      <td>0.130934</td>\n",
       "      <td>0.442166</td>\n",
       "      <td>-0.064023</td>\n",
       "      <td>-0.844747</td>\n",
       "      <td>-0.490438</td>\n",
       "      <td>-0.478358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350878</td>\n",
       "      <td>0.293865</td>\n",
       "      <td>-0.515041</td>\n",
       "      <td>-0.317028</td>\n",
       "      <td>-0.061153</td>\n",
       "      <td>0.593661</td>\n",
       "      <td>-0.321454</td>\n",
       "      <td>-0.114020</td>\n",
       "      <td>0.256753</td>\n",
       "      <td>filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>-0.568426</td>\n",
       "      <td>-0.211157</td>\n",
       "      <td>0.422359</td>\n",
       "      <td>0.468056</td>\n",
       "      <td>-0.114488</td>\n",
       "      <td>-0.638892</td>\n",
       "      <td>-0.495567</td>\n",
       "      <td>0.169151</td>\n",
       "      <td>0.074504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372135</td>\n",
       "      <td>-0.422320</td>\n",
       "      <td>0.860934</td>\n",
       "      <td>0.485809</td>\n",
       "      <td>0.015329</td>\n",
       "      <td>0.191224</td>\n",
       "      <td>0.095379</td>\n",
       "      <td>-0.069076</td>\n",
       "      <td>-0.161135</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>0.142577</td>\n",
       "      <td>-0.224124</td>\n",
       "      <td>0.232275</td>\n",
       "      <td>0.147007</td>\n",
       "      <td>0.154988</td>\n",
       "      <td>0.332796</td>\n",
       "      <td>-0.194241</td>\n",
       "      <td>0.187481</td>\n",
       "      <td>-0.269601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185737</td>\n",
       "      <td>0.637940</td>\n",
       "      <td>-0.538573</td>\n",
       "      <td>-0.351984</td>\n",
       "      <td>0.111684</td>\n",
       "      <td>0.232872</td>\n",
       "      <td>-0.361011</td>\n",
       "      <td>-0.579879</td>\n",
       "      <td>0.075471</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>29109</td>\n",
       "      <td>-0.300061</td>\n",
       "      <td>0.214009</td>\n",
       "      <td>0.576389</td>\n",
       "      <td>0.148372</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>-0.372686</td>\n",
       "      <td>-0.369670</td>\n",
       "      <td>-0.440753</td>\n",
       "      <td>-0.819607</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715899</td>\n",
       "      <td>-0.009404</td>\n",
       "      <td>-0.057255</td>\n",
       "      <td>-0.170222</td>\n",
       "      <td>-0.227720</td>\n",
       "      <td>0.092222</td>\n",
       "      <td>0.120519</td>\n",
       "      <td>-0.384632</td>\n",
       "      <td>0.114726</td>\n",
       "      <td>irish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>11462</td>\n",
       "      <td>-0.176457</td>\n",
       "      <td>-0.039776</td>\n",
       "      <td>0.616104</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>0.779065</td>\n",
       "      <td>0.319951</td>\n",
       "      <td>-0.651085</td>\n",
       "      <td>0.065457</td>\n",
       "      <td>-0.498473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303166</td>\n",
       "      <td>0.688057</td>\n",
       "      <td>-0.367985</td>\n",
       "      <td>-0.498265</td>\n",
       "      <td>-0.109980</td>\n",
       "      <td>0.475887</td>\n",
       "      <td>-0.001684</td>\n",
       "      <td>0.067849</td>\n",
       "      <td>0.424963</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39771</th>\n",
       "      <td>2238</td>\n",
       "      <td>-0.019574</td>\n",
       "      <td>0.188493</td>\n",
       "      <td>0.143884</td>\n",
       "      <td>0.178563</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>-0.373238</td>\n",
       "      <td>-0.474058</td>\n",
       "      <td>0.177133</td>\n",
       "      <td>0.126927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269083</td>\n",
       "      <td>0.186699</td>\n",
       "      <td>0.295708</td>\n",
       "      <td>-0.089674</td>\n",
       "      <td>-0.566020</td>\n",
       "      <td>0.345784</td>\n",
       "      <td>-0.369699</td>\n",
       "      <td>-0.479011</td>\n",
       "      <td>0.361121</td>\n",
       "      <td>irish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39772</th>\n",
       "      <td>41882</td>\n",
       "      <td>0.776432</td>\n",
       "      <td>0.437692</td>\n",
       "      <td>0.641111</td>\n",
       "      <td>0.406933</td>\n",
       "      <td>0.145073</td>\n",
       "      <td>0.024049</td>\n",
       "      <td>-0.334166</td>\n",
       "      <td>-0.259979</td>\n",
       "      <td>-0.174525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104134</td>\n",
       "      <td>0.544601</td>\n",
       "      <td>-1.015185</td>\n",
       "      <td>-0.371715</td>\n",
       "      <td>-0.013743</td>\n",
       "      <td>0.481623</td>\n",
       "      <td>0.141545</td>\n",
       "      <td>-0.111951</td>\n",
       "      <td>-0.463663</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39773</th>\n",
       "      <td>2362</td>\n",
       "      <td>1.215361</td>\n",
       "      <td>0.019611</td>\n",
       "      <td>0.159291</td>\n",
       "      <td>0.519294</td>\n",
       "      <td>0.168343</td>\n",
       "      <td>-0.048764</td>\n",
       "      <td>-0.614092</td>\n",
       "      <td>-0.198759</td>\n",
       "      <td>-0.586713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>-0.340644</td>\n",
       "      <td>-0.162854</td>\n",
       "      <td>-0.223557</td>\n",
       "      <td>-0.023427</td>\n",
       "      <td>0.066629</td>\n",
       "      <td>0.117628</td>\n",
       "      <td>-0.421405</td>\n",
       "      <td>-0.342819</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39774 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         0         1         2         3         4         5  \\\n",
       "0      10259  0.463036  0.043366  0.148925 -0.274926  0.652883  0.115647   \n",
       "1      25693  0.223341  0.731181  0.343865  0.254070  0.232782 -0.089698   \n",
       "2      20130  0.411820  0.636279  0.355501  0.130934  0.442166 -0.064023   \n",
       "3      22213 -0.568426 -0.211157  0.422359  0.468056 -0.114488 -0.638892   \n",
       "4      13162  0.142577 -0.224124  0.232275  0.147007  0.154988  0.332796   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "39769  29109 -0.300061  0.214009  0.576389  0.148372  0.060303 -0.372686   \n",
       "39770  11462 -0.176457 -0.039776  0.616104  0.014460  0.779065  0.319951   \n",
       "39771   2238 -0.019574  0.188493  0.143884  0.178563  0.682860 -0.373238   \n",
       "39772  41882  0.776432  0.437692  0.641111  0.406933  0.145073  0.024049   \n",
       "39773   2362  1.215361  0.019611  0.159291  0.519294  0.168343 -0.048764   \n",
       "\n",
       "              6         7         8  ...       759       760       761  \\\n",
       "0     -0.791759 -0.007681  0.531001  ...  0.354413 -0.316524  0.198050   \n",
       "1     -0.678553  0.145089 -0.042785  ...  0.029557  0.033568  0.062671   \n",
       "2     -0.844747 -0.490438 -0.478358  ...  0.350878  0.293865 -0.515041   \n",
       "3     -0.495567  0.169151  0.074504  ... -0.372135 -0.422320  0.860934   \n",
       "4     -0.194241  0.187481 -0.269601  ...  0.185737  0.637940 -0.538573   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "39769 -0.369670 -0.440753 -0.819607  ... -0.715899 -0.009404 -0.057255   \n",
       "39770 -0.651085  0.065457 -0.498473  ...  0.303166  0.688057 -0.367985   \n",
       "39771 -0.474058  0.177133  0.126927  ... -0.269083  0.186699  0.295708   \n",
       "39772 -0.334166 -0.259979 -0.174525  ...  0.104134  0.544601 -1.015185   \n",
       "39773 -0.614092 -0.198759 -0.586713  ...  0.185600 -0.340644 -0.162854   \n",
       "\n",
       "            762       763       764       765       766       767        label  \n",
       "0     -0.035833  0.038994  0.123171 -0.514503 -0.409309  0.312318        greek  \n",
       "1     -0.010367 -0.152798 -0.075444 -0.185032 -0.040249 -0.040383  southern_us  \n",
       "2     -0.317028 -0.061153  0.593661 -0.321454 -0.114020  0.256753     filipino  \n",
       "3      0.485809  0.015329  0.191224  0.095379 -0.069076 -0.161135       indian  \n",
       "4     -0.351984  0.111684  0.232872 -0.361011 -0.579879  0.075471       indian  \n",
       "...         ...       ...       ...       ...       ...       ...          ...  \n",
       "39769 -0.170222 -0.227720  0.092222  0.120519 -0.384632  0.114726        irish  \n",
       "39770 -0.498265 -0.109980  0.475887 -0.001684  0.067849  0.424963      italian  \n",
       "39771 -0.089674 -0.566020  0.345784 -0.369699 -0.479011  0.361121        irish  \n",
       "39772 -0.371715 -0.013743  0.481623  0.141545 -0.111951 -0.463663      chinese  \n",
       "39773 -0.223557 -0.023427  0.066629  0.117628 -0.421405 -0.342819      mexican  \n",
       "\n",
       "[39774 rows x 770 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/embedded_whats_cooking/embedded_train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d751a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spanish', 'french', 'chinese', 'thai', 'moroccan', 'russian', 'brazilian', 'vietnamese', 'irish', 'italian', 'korean', 'cajun_creole', 'southern_us', 'greek', 'british', 'mexican', 'filipino', 'jamaican', 'indian', 'japanese'}\n",
      "20\n",
      "====================\n",
      "{'spanish': 0, 'french': 1, 'chinese': 2, 'thai': 3, 'moroccan': 4, 'russian': 5, 'brazilian': 6, 'vietnamese': 7, 'irish': 8, 'italian': 9, 'korean': 10, 'cajun_creole': 11, 'southern_us': 12, 'greek': 13, 'british': 14, 'mexican': 15, 'filipino': 16, 'jamaican': 17, 'indian': 18, 'japanese': 19}\n"
     ]
    }
   ],
   "source": [
    "y_labels = df[\"label\"].tolist()\n",
    "\n",
    "print(set(y_labels))\n",
    "\n",
    "print(len(set(y_labels)))\n",
    "\n",
    "label_dict = {}\n",
    "\n",
    "count = 0\n",
    "for ele in set(y_labels):\n",
    "    label_dict[ele] = count\n",
    "    count += 1\n",
    "print(\"=\"*20)\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e81bf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39774\n",
      "[13, 12, 16, 18, 18, 17, 0, 9, 15, 9, 9, 2, 9, 15, 9, 18, 14, 9, 3, 7]\n"
     ]
    }
   ],
   "source": [
    "encoded_labels = []\n",
    "for label in y_labels:\n",
    "    encoded_labels.append(label_dict[label])\n",
    "print(len(encoded_labels))\n",
    "print(encoded_labels[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f037ee23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0.463036</td>\n",
       "      <td>0.043366</td>\n",
       "      <td>0.148925</td>\n",
       "      <td>-0.274926</td>\n",
       "      <td>0.652883</td>\n",
       "      <td>0.115647</td>\n",
       "      <td>-0.791759</td>\n",
       "      <td>-0.007681</td>\n",
       "      <td>0.531001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158843</td>\n",
       "      <td>0.354413</td>\n",
       "      <td>-0.316524</td>\n",
       "      <td>0.198050</td>\n",
       "      <td>-0.035833</td>\n",
       "      <td>0.038994</td>\n",
       "      <td>0.123171</td>\n",
       "      <td>-0.514503</td>\n",
       "      <td>-0.409309</td>\n",
       "      <td>0.312318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>0.223341</td>\n",
       "      <td>0.731181</td>\n",
       "      <td>0.343865</td>\n",
       "      <td>0.254070</td>\n",
       "      <td>0.232782</td>\n",
       "      <td>-0.089698</td>\n",
       "      <td>-0.678553</td>\n",
       "      <td>0.145089</td>\n",
       "      <td>-0.042785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126155</td>\n",
       "      <td>0.029557</td>\n",
       "      <td>0.033568</td>\n",
       "      <td>0.062671</td>\n",
       "      <td>-0.010367</td>\n",
       "      <td>-0.152798</td>\n",
       "      <td>-0.075444</td>\n",
       "      <td>-0.185032</td>\n",
       "      <td>-0.040249</td>\n",
       "      <td>-0.040383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.411820</td>\n",
       "      <td>0.636279</td>\n",
       "      <td>0.355501</td>\n",
       "      <td>0.130934</td>\n",
       "      <td>0.442166</td>\n",
       "      <td>-0.064023</td>\n",
       "      <td>-0.844747</td>\n",
       "      <td>-0.490438</td>\n",
       "      <td>-0.478358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.486408</td>\n",
       "      <td>0.350878</td>\n",
       "      <td>0.293865</td>\n",
       "      <td>-0.515041</td>\n",
       "      <td>-0.317028</td>\n",
       "      <td>-0.061153</td>\n",
       "      <td>0.593661</td>\n",
       "      <td>-0.321454</td>\n",
       "      <td>-0.114020</td>\n",
       "      <td>0.256753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.568426</td>\n",
       "      <td>-0.211157</td>\n",
       "      <td>0.422359</td>\n",
       "      <td>0.468056</td>\n",
       "      <td>-0.114488</td>\n",
       "      <td>-0.638892</td>\n",
       "      <td>-0.495567</td>\n",
       "      <td>0.169151</td>\n",
       "      <td>0.074504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973956</td>\n",
       "      <td>-0.372135</td>\n",
       "      <td>-0.422320</td>\n",
       "      <td>0.860934</td>\n",
       "      <td>0.485809</td>\n",
       "      <td>0.015329</td>\n",
       "      <td>0.191224</td>\n",
       "      <td>0.095379</td>\n",
       "      <td>-0.069076</td>\n",
       "      <td>-0.161135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0.142577</td>\n",
       "      <td>-0.224124</td>\n",
       "      <td>0.232275</td>\n",
       "      <td>0.147007</td>\n",
       "      <td>0.154988</td>\n",
       "      <td>0.332796</td>\n",
       "      <td>-0.194241</td>\n",
       "      <td>0.187481</td>\n",
       "      <td>-0.269601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339153</td>\n",
       "      <td>0.185737</td>\n",
       "      <td>0.637940</td>\n",
       "      <td>-0.538573</td>\n",
       "      <td>-0.351984</td>\n",
       "      <td>0.111684</td>\n",
       "      <td>0.232872</td>\n",
       "      <td>-0.361011</td>\n",
       "      <td>-0.579879</td>\n",
       "      <td>0.075471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.300061</td>\n",
       "      <td>0.214009</td>\n",
       "      <td>0.576389</td>\n",
       "      <td>0.148372</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>-0.372686</td>\n",
       "      <td>-0.369670</td>\n",
       "      <td>-0.440753</td>\n",
       "      <td>-0.819607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156608</td>\n",
       "      <td>-0.715899</td>\n",
       "      <td>-0.009404</td>\n",
       "      <td>-0.057255</td>\n",
       "      <td>-0.170222</td>\n",
       "      <td>-0.227720</td>\n",
       "      <td>0.092222</td>\n",
       "      <td>0.120519</td>\n",
       "      <td>-0.384632</td>\n",
       "      <td>0.114726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.176457</td>\n",
       "      <td>-0.039776</td>\n",
       "      <td>0.616104</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>0.779065</td>\n",
       "      <td>0.319951</td>\n",
       "      <td>-0.651085</td>\n",
       "      <td>0.065457</td>\n",
       "      <td>-0.498473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265406</td>\n",
       "      <td>0.303166</td>\n",
       "      <td>0.688057</td>\n",
       "      <td>-0.367985</td>\n",
       "      <td>-0.498265</td>\n",
       "      <td>-0.109980</td>\n",
       "      <td>0.475887</td>\n",
       "      <td>-0.001684</td>\n",
       "      <td>0.067849</td>\n",
       "      <td>0.424963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39771</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.019574</td>\n",
       "      <td>0.188493</td>\n",
       "      <td>0.143884</td>\n",
       "      <td>0.178563</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>-0.373238</td>\n",
       "      <td>-0.474058</td>\n",
       "      <td>0.177133</td>\n",
       "      <td>0.126927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125620</td>\n",
       "      <td>-0.269083</td>\n",
       "      <td>0.186699</td>\n",
       "      <td>0.295708</td>\n",
       "      <td>-0.089674</td>\n",
       "      <td>-0.566020</td>\n",
       "      <td>0.345784</td>\n",
       "      <td>-0.369699</td>\n",
       "      <td>-0.479011</td>\n",
       "      <td>0.361121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39772</th>\n",
       "      <td>2</td>\n",
       "      <td>0.776432</td>\n",
       "      <td>0.437692</td>\n",
       "      <td>0.641111</td>\n",
       "      <td>0.406933</td>\n",
       "      <td>0.145073</td>\n",
       "      <td>0.024049</td>\n",
       "      <td>-0.334166</td>\n",
       "      <td>-0.259979</td>\n",
       "      <td>-0.174525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224841</td>\n",
       "      <td>0.104134</td>\n",
       "      <td>0.544601</td>\n",
       "      <td>-1.015185</td>\n",
       "      <td>-0.371715</td>\n",
       "      <td>-0.013743</td>\n",
       "      <td>0.481623</td>\n",
       "      <td>0.141545</td>\n",
       "      <td>-0.111951</td>\n",
       "      <td>-0.463663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39773</th>\n",
       "      <td>15</td>\n",
       "      <td>1.215361</td>\n",
       "      <td>0.019611</td>\n",
       "      <td>0.159291</td>\n",
       "      <td>0.519294</td>\n",
       "      <td>0.168343</td>\n",
       "      <td>-0.048764</td>\n",
       "      <td>-0.614092</td>\n",
       "      <td>-0.198759</td>\n",
       "      <td>-0.586713</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630365</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>-0.340644</td>\n",
       "      <td>-0.162854</td>\n",
       "      <td>-0.223557</td>\n",
       "      <td>-0.023427</td>\n",
       "      <td>0.066629</td>\n",
       "      <td>0.117628</td>\n",
       "      <td>-0.421405</td>\n",
       "      <td>-0.342819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39774 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        y         0         1         2         3         4         5  \\\n",
       "0      13  0.463036  0.043366  0.148925 -0.274926  0.652883  0.115647   \n",
       "1      12  0.223341  0.731181  0.343865  0.254070  0.232782 -0.089698   \n",
       "2      16  0.411820  0.636279  0.355501  0.130934  0.442166 -0.064023   \n",
       "3      18 -0.568426 -0.211157  0.422359  0.468056 -0.114488 -0.638892   \n",
       "4      18  0.142577 -0.224124  0.232275  0.147007  0.154988  0.332796   \n",
       "...    ..       ...       ...       ...       ...       ...       ...   \n",
       "39769   8 -0.300061  0.214009  0.576389  0.148372  0.060303 -0.372686   \n",
       "39770   9 -0.176457 -0.039776  0.616104  0.014460  0.779065  0.319951   \n",
       "39771   8 -0.019574  0.188493  0.143884  0.178563  0.682860 -0.373238   \n",
       "39772   2  0.776432  0.437692  0.641111  0.406933  0.145073  0.024049   \n",
       "39773  15  1.215361  0.019611  0.159291  0.519294  0.168343 -0.048764   \n",
       "\n",
       "              6         7         8  ...       758       759       760  \\\n",
       "0     -0.791759 -0.007681  0.531001  ... -0.158843  0.354413 -0.316524   \n",
       "1     -0.678553  0.145089 -0.042785  ...  0.126155  0.029557  0.033568   \n",
       "2     -0.844747 -0.490438 -0.478358  ... -0.486408  0.350878  0.293865   \n",
       "3     -0.495567  0.169151  0.074504  ...  0.973956 -0.372135 -0.422320   \n",
       "4     -0.194241  0.187481 -0.269601  ... -0.339153  0.185737  0.637940   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "39769 -0.369670 -0.440753 -0.819607  ...  0.156608 -0.715899 -0.009404   \n",
       "39770 -0.651085  0.065457 -0.498473  ... -0.265406  0.303166  0.688057   \n",
       "39771 -0.474058  0.177133  0.126927  ...  0.125620 -0.269083  0.186699   \n",
       "39772 -0.334166 -0.259979 -0.174525  ... -0.224841  0.104134  0.544601   \n",
       "39773 -0.614092 -0.198759 -0.586713  ... -0.630365  0.185600 -0.340644   \n",
       "\n",
       "            761       762       763       764       765       766       767  \n",
       "0      0.198050 -0.035833  0.038994  0.123171 -0.514503 -0.409309  0.312318  \n",
       "1      0.062671 -0.010367 -0.152798 -0.075444 -0.185032 -0.040249 -0.040383  \n",
       "2     -0.515041 -0.317028 -0.061153  0.593661 -0.321454 -0.114020  0.256753  \n",
       "3      0.860934  0.485809  0.015329  0.191224  0.095379 -0.069076 -0.161135  \n",
       "4     -0.538573 -0.351984  0.111684  0.232872 -0.361011 -0.579879  0.075471  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "39769 -0.057255 -0.170222 -0.227720  0.092222  0.120519 -0.384632  0.114726  \n",
       "39770 -0.367985 -0.498265 -0.109980  0.475887 -0.001684  0.067849  0.424963  \n",
       "39771  0.295708 -0.089674 -0.566020  0.345784 -0.369699 -0.479011  0.361121  \n",
       "39772 -1.015185 -0.371715 -0.013743  0.481623  0.141545 -0.111951 -0.463663  \n",
       "39773 -0.162854 -0.223557 -0.023427  0.066629  0.117628 -0.421405 -0.342819  \n",
       "\n",
       "[39774 rows x 769 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y\"] = encoded_labels\n",
    "df = df.drop(['label', 'id'], axis=1)\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83853c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model running is: LDA\n",
      "The average score of LDA is 0.7152134560018031 with std of 0.0041377045200902225\n",
      "Time to run LDA is 226.42991995811462\n",
      "====================\n",
      "The model running is: Nearest Neighbors\n",
      "The average score of Nearest Neighbors is 0.6732212155785142 with std of 0.004963808356907633\n",
      "Time to run Nearest Neighbors is 344.6660888195038\n",
      "====================\n",
      "The model running is: RBF SVM\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-23505e9c2a2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtime_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mscore_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    441\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    244\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    245\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 246\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    247\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    248\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             self._probB, self.fit_status_ = libsvm.fit(\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scoring = \"accuracy\"\n",
    "data = df.to_numpy()\n",
    "X = data[:, 1:]\n",
    "y = data[:, 0]\n",
    "\n",
    "score_dict = {}\n",
    "time_dict = {}\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, model in models:\n",
    "    print(\"The model running is: \" + name)\n",
    "    time_start = time()\n",
    "    kfold = RepeatedStratifiedKFold()\n",
    "    scores = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "    time_end = time()\n",
    "    score_dict[name] = scores.mean()\n",
    "    time_elapsed = time_end - time_start \n",
    "    time_dict[name] = time_elapsed\n",
    "    print(\"The average score of \" + name + \" is\", scores.mean(), \"with std of\", scores.std())\n",
    "    print(\"Time to run \" + name + \" is\", str(time_elapsed))\n",
    "    print(\"=\" * 20)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10741c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"score_dict is\", score_dict)\n",
    "print(\"time_dict is\", time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0206da",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_name = names\n",
    "accuracy_list = []\n",
    "time_list = []\n",
    "for name in classifier_name:\n",
    "    if name == 'RandomForest' or name == \"RBF SVM\":\n",
    "        continue\n",
    "    accuracy_list.append(score_dict[name])\n",
    "    time_list.append(time_dict[name])\n",
    "recording = {\"Accuracy\": accuracy_list, \"Runtime(s)\":time_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef9979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_record = pd.DataFrame(recording, index = classifier_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e720d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_record.to_csv(\"output/classifiers_accuracy_runtime.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
